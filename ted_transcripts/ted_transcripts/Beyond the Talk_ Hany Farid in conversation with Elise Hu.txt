 you're listening to TED Talks Daily, where we bring you new ideas and conversations to spark your curiosity every day. I'm your host, Elise Hu. Digital forensic scientist Hani Farid warns we're at a pivotal fork in the road when it comes to what our eyes are seeing and what's real. Hani, who specializes in identifying AI-generated imagery and video, explained in his TED Talk how generative AI is fundamentally changing our very understanding of truth. After Hani got off stage, we sat down to talk more about the rapid growth of generative AI and its vast implications for how we engage with media, politics, and, well, pretty much everything. We also talk about the very real dangers of deepfakes, the changing face of news globally, and why it's so important to be skeptical and diligent about everything we see and hear. Well, thank you for sitting down with me. It's good to be here. Talk to us a little bit just about the big idea of your TED Talk because we are all engaging in a world of visual imagery these days. But so much of it is fake? Correct. You can think about what I was talking about in several levels. Here's the big level, which is trust. It's not about images. It's not about videos. It's not about deepfakes. It's not about anything. It's not about fake news. It's about trust. How do you trust anything anymore? Who do you trust? Where do you trust? And I would contend that if you can't trust the information we get, we can't do anything. We can't have open and fair elections. We can't tackle climate change. We can't tackle a global pandemic. We can't have stable societies and economies. So I think there's this sort of bigger story here that we have slowly but surely started to erode our ability to trust each other, trust organizations, trust the media, trust anybody. And that feels to me like a death blow to a society. There's two reasons for it. One is what I just enumerated. We can't respond if we don't agree on basic facts. But the other one is how do you regain trust once you've lost it? How do we? You don't. That's the problem because you need to believe in the media. You need to believe in the experts. You need to trust your government. And if you don't have that, how do you regain it? And now you have the mother of all chicken and egg problems. So what's so fascinating to me as a technologist about the internet was that it was designed to democratize access to knowledge and information. And it did, but it didn't distinguish between good information and bad information. No, it didn't. And arguably, the bad information overrides the good information by a big margin. And I think we are repeating exactly the same mistakes with this AI generation because what are AI models? They're trained on the internet. The internet is a cesspool. Trash in, trash out. Trash in, trash out. Right? And so I worry that so many people's lives sort of start the day and end the day on these devices. And we are being fed garbage, junk food, to keep us clicking and liking, to raise profits for a couple of five companies in the world. And I think we're burning the place to the ground, honestly. Now, one level under that is the deep fakes and the fake images and the fake videos that are being weaponized against individuals and organizations. But it's a subset of a much larger issue that I think we all sort of know is there. And what I find so fascinating about this conversation is I can't tell you how many people I have this conversation with where I say, we should get off of social media. And they're like, yeah, yeah. And they applaud. And then they're like tweeting about that. I'm like, really? It really boomerangs back on itself. Yeah. Capitalism has such a way of absorbing its own critiques and then just moving forward. Yeah. Exactly. So if trust is lost or trust is broken and we can't get it back, then is the cow out of the barn? What do we do? How do I not just curl up in fetal position? And then knock it out of bed in the morning. Yeah. Well, I will tell you there are days where I think, yeah, this is over. This is a good experiment, but this is the beginning of the end. There are other days where I'm more hopeful. But I do think that if we are passive, we just say it'll work itself out. This is going to end badly. We are on a path of no return. We have to make a conscious choice to change. And that's going to require not one or two or three, but a lot of big moves and a lot of small moves too. We've got to get the tech companies in order. We've got to get governments to be more responsive. We've got to get better education in the schools about critical thinking and what the internet is and what it is not. And there's a lot of moves to be made. And at a time, I don't want to be political about this, without a lot of leadership coming out of the US. I don't see that happening in the next three years. And I don't know that we have more than three years before this gets really, really weird. Yeah. It already feels really, really weird. It's weird. And here's what I can tell you. I'm a technologist and I've been in this space for a long time. We used to measure advances in technology in 12 to 18 months. We now measure in 12 to 18 days. I mean, a couple of weeks go by, we're like, well, where did that come from? It is fast. And here's the thing you have to understand about AI. It's starting to program itself. These AI models are starting to be so good. Isn't that what they're designed to do? Yes. To teach themselves. Yeah. And so then, you know, they start to sort of get out of our control. And when you start putting these systems in critical decision-making places that, by the way, we don't understand these systems. We don't thoroughly understand them. They have emergent behaviors and people are like, well, where did that come from? And that is disconcerting. Yeah. Would guardrails, would regulation or guardrails even be able to do anything about these advances given that AI is kind of on its own already? Yeah. So I would like to see regulation. I would like for our US government and our European government and our Australian and all the governments to say, look, guys, let's not repeat the mistake of the last 20 years. We tried the hands-off move fast and break things and it didn't work. So let's get better. But it's not happening. So the Europeans have moved pretty well. They have the DSA and the DMA, which are trying to put guardrails. The Brits have some good guardrails, but okay, they can help a relatively small percentage of the world. But what do we do in 85, 90% of the world? And if the US is not here, we are nowhere. And we are nowhere. And the other thing with regulation is that it moves spectacularly slowly with lobbying efforts from now trillion-dollar companies watering everything down in their favor. So I'm not optimistic. I think if you are looking for external relief, it has to come from litigation, not regulation. That is, you have to start holding companies responsible for the harms that they do. Why are the products that we have in our pockets relatively safe? Because we told these companies that if you create a product that either you knew or should have known would be harmful, I'm going to sue you back to the dark ages. And we got product safety. Yeah. It was good. I mean, it happened with cigarettes. It happened with cigarettes. It happened with a lot of products. And so the physical products, the foods, the food we eat is relatively safe, right? The airlines, everything is relatively safe. But somehow in the digital world, we thought, nah, it's the internet. But it's not the internet. There is no more online world. What could go wrong? Yeah. And this is the thing is we have to start holding these companies responsible for the harms that they do. And when that happens, they internalize that. And they say, okay, we can move fast and break things and get sued back to the dark ages, or we can slow the hell down, build these things by safety, by design, not as a third or fourth afterthought, and then not get sued back to the dark ages. You have to create the right incentives. And when we don't have the right incentives, the companies are going to do what the companies do. There's also kind of a collective action problem too, right? Like you can prescribe various solutions for individuals. Like I can go on digital detox and I might be able to get off of social media, but not if the collective isn't off social media. And you're also not the customer. Whether you're on there or not is irrelevant. You're the product, right? The customer or the advertisers. Right. It's my data. Yeah. Yeah. And you're absolutely right. And, you know, for young people, I'm actually fairly sympathetic, right? If every single one of their friends are on these apps, yeah, what are you going to do? Right. I mean, so I am sympathetic to that. And I do think that, although I said this in my talk, get off of social media. And I mean that you really should, by the way, the evidence is overwhelming. It is bad for you. It's bad for your mental health. It's bad for your physical health. And I swear to God, it drops your IQ by 20 points. You should get off of it. But I'm also realistic that, you know, berating people for doing something that they know is bad for them is telling people who like to stop eating potato chips, right? I just ate a bag of potato chips, by the way. Delicious. Fantastic. So I think we have to give them better options. I think what we have to do is say, look, this stuff sucks and it's bad for you, but here's something that's good, right? And it doesn't suck and it's good for you. So I think I would like to see the venture capital community start to try to invest in companies that are just better, right? This is a group of people, by the way, that I think get off without a lot of criticism. All of these tech companies are VC backed, right? And they are the ones that are driving. They're making the bets. They're absolutely making the bets. And they are betting on a model that works, right? Move fast and break things. So I do think we have to give better options. And this is where governments can step in and start creating incentives for companies to do better, right? This is something we can do. We don't need regulation for that. And it's not, frankly, not that controversial. But I think we have to give people a better option and we haven't done that yet. Can I give you one analogy to this? Sure. So when you go to the grocery store, they should make the junk food hard to find. They should make the healthy food easy to find. They should tax the stuff that's bad for you and make it more expensive. So we're not telling you not to do it, but we're going to de-incentivize it. So we can do that with our digital worlds. We just have to be motivated to do it. Yeah. Slapping taxes on what is considered like not good for you. Syntaxes. Yeah. Right? Syntaxes. Yeah. Tobacco. Alcohol. That has certainly happened in the past. Yeah. And why not open our minds to happening, to doing that again? I want to talk about the young people because you mentioned young people and what we do about that. And the fact that so many of them search TikTok for information. What do you say to parents? What kind of advice do you give to parents for their kids and for teaching their kids to become more literate when it comes to the information that they encounter when there is so much trash out there? I got to tell you, one of the things that makes me crazy because I teach at UC Berkeley and I interact with a lot of young people who I generally adore, by the way. I think they, even if their heads aren't in the right place, their hearts are in the right place. I can't tell you how many conversations I have with this. I was watching on TikTok about Gaza, Ukraine, climate change. And I always say, don't finish that sentence because there's nothing at the end of that sentence that starts with, I saw on TikTok that I am interested in. But like it or not, that is a primary news source. It is a primary news source. And it is horrifying. It is horrifying. And so what do you tell parents? I don't know. I mean, thank God I'm not a parent, honestly, because I don't know how people do it. I mean, honestly, it is unbelievably hard. Here's the only thing I can suggest. And this is not, it's a little bit unfair to put this on the parents. I think we have to put this on the schools is we have to teach critical thinking. We have to teach people that you are being manipulated on social media. You are being delivered those videos with a very specific algorithm to keep you clicking for as long as possible to deliver ads. That's what is happening. And that's, by the way, not that different than the tobacco industry manipulating nicotine levels to keep people addicted. It's the same thing. Or Las Vegas, the way they design machines to keep you, to keep putting money into the machine so that you separate it from yourself. So I think we have to teach critical thinking. I think we have to teach people the difference between a story in the Associated Press or Reuters or Algeant France and some random video on TikTok. Those are not the same thing. Okay. Right? So I think a lot of this is about education and about reminding people that if you want to use TikTok for entertainment, I'm fine with that. But it's not a place to get news and information. Like, just knock it off. That's not what it was designed for. Real quick, how do you teach or what do you teach to folks who want to be able to tell the difference between fake or real imagery? All right. A couple of things. One is stop getting your news from social media because that's literally— Step number one. No, step number one. Step number two is whether you like mainstream media outlets or not, they do a pretty good job of getting it right. And I know this because I talk to them every single day that when images come out of war zones or natural disasters or whatever it is, they are vetted pretty carefully. No, there's a methodology. There's a methodology. And there's also a consequence for getting it wrong. Right? So if you want reliable information, get the hell off of social media and go to places that have editorial and journalistic standards. Okay. Number three is you cannot do this well. I do this for a living and I'm pretty good at it and I've been doing it for 30 years and it's hard and it's getting harder. And here's the real danger. I could right now name five things that I can teach you to look at an image. But here's the problem is in six months, it probably won't be true anymore. And now you have this false sense of confidence, right? I call it the arrogance ignorance problem, right? You got to understand that this is incredibly hard. You are not well suited to do this. It's sort of like saying, how do you teach somebody to give themselves surgery? You don't. You go to a doctor who went to medical school. That's what you do. You leave this to professionals. Right. You're not, you're not, you're not going to be an investigative journalist. Right. I hate to tell you this. Right. Do what you do well and let other people do what they do well and trust that they're going to do their best to get you information. Yeah. That's it. All right. Last question. Since the cow is kind of out of the barn or the toothpaste is out of the tube, whatever analogy you want to use. I've never heard the cow in the cow barn, by the way. I'm from Texas. Okay. That's where it came from. That's why. That's why. I've got to like bring my Texas. Cat out of the bag. No? Okay. All right. How do you convince people that things are fake when they're not real? Yeah. This is hard. So I'll give you a couple of examples. We live in a very polarized time and I get requests and emails from all kinds of news outlets to analyze things that are harmful to Donald Trump or things that were harmful to Kamala Harris. And when I say that something that is harmful to Donald Trump is real, I get a phenomenal amount of hate mail from the right. When I say something that is helpful to Donald Trump and I say that it is real, I get hate mail from the left. People don't want to hear things that they don't agree with. Right. And this is very, very bad. And I don't know how to fix that. This is a bit of a cop out, but I think what I do is necessary, but it's not sufficient. It's necessary to know what's what, but it's sort of like medicine. It doesn't always go down right. And I can tell you, this is not a partisan issue. I get just as much hate mail, maybe a little bit more from the right than the left, but I get a lot of hate mail from people who don't like what I have to say because it doesn't conform to their worldview. Yeah. I can't tell you how many emails I get from people who say, hey, you should look at this and tell me what you think because you're the world's leading expert on this. And I'll respond, hey, we've looked at this. Here's the fact check. And they wrote back being like, you're a moron. I'm like, okay, but you're the one who wrote to me telling me I'm the world's leading expert. So what are we doing here? Yeah. Yeah. Right. I'm only the world leading expert when I agree with you. When I agree with you. It's not the way the world works. And here's the thing is you can sort of blame people for being knuckleheads, but part of it is also that we are living in the mother of all echo chambers because of social media. Yeah. And we also have, we're only human. We have our own cognitive biases too. We absolutely do. We absolutely do. And I think people also interact with each other online in a way that they wouldn't do like this. I can't tell you the number of people who have threatened to kill me on email or voicemail for that matter. Sometimes they're handwritten letters. Those are particularly weird. Yeah. They just went through so much effort to get to me. You put that in the mail? I know, exactly. Yeah. So, but I do worry that we have demonized the people we disagree with so much so that we can't even listen anymore. And now we come back to trust, right? So I don't know how to fix that. I don't know how to fix it, but I think we have to fix it. Yeah. Thank you so much for sitting down with me. Before we wrap up completely, I have some rapid fire questions. Good. I love rapid fire. Okay. Okay. Here we go. What does innovation or a good idea look or feel like to you? I don't know, but I know when I get it. Okay. What's something new that you brought into your life in 2025 that didn't exist before? Oh my God. Like a physical thing? Or are you a new practice? Are you like playing tennis or anything? Are you doing anything new? God, I don't have an answer for this. This is terrible. What are you hoping to leave behind this year? Ah. I co-founded a company to try to restore trust and I'm hoping that we will at least be somewhat successful. Okay. That'll be the new thing you bring into the world and you get to leave it behind. It's a legacy too. That's a good one. All right. Off the TED stage, what is a fun talent, skill, hobby, obsession that you have that you love so much that you could give another TED talk? Just about that. Another TED talk on it. Okay. Favorite obsessions are anything with two wheels. I ride a Harley Davidson motorcycle. I'm a road cyclist. I'm a mountain biker. I'm not good enough at any of those things to give a TED talk on. But if I had to give another one, this is what it would be on because I give this advice to students all the time. Okay. What's your favorite is that you got to find a way to unplug. You got to. There is nothing like being out in nature. Here we are in this beautiful Vancouver. There is nothing like it. I mean, 20 minutes with a hike in the woods is better than anything else. Like you got to unplug. Touch grass. Yeah. You got to put the device down. You got to get away from it. And I know it's really hard, but once you start doing it, it's like the mother of all therapies. Yeah. What's your most treasured memory? My family's originally from Egypt and I was born in Germany and we immigrated when I was very young. But as young kids, we would go to Egypt every year, every year. And probably my most cherished memories were in Cairo with my grandparents. And it was such a different time. They would just give us a a few pennies and we'd go down to the local baker and get the fresh bread and the smell of that and the streets of Cairo and going back home and eating incredible food. I have such fond memories of that. Food is so evocative too. And the smells, that smell of that fresh bread. Well, maybe along the lines of that, what would constitute a perfect day for you? I mean, you can just list off a few things. Oh yeah. A couple of things. On my bike all day long, century ride, put in 100 miles with friends and end up at a phenomenal restaurant for a meal. By the way, if you've ever been 100 miles, there is nothing that tastes nearly as good as whatever you're eating at the end of those 100 miles. That's a good day for me. That's beautiful. All right. Two-sided question. Yeah. Final two. Yeah. What are you worried about? What's giving you hope? I'm worried about everything. I really do. I'm sure this interview is making me feel great, honey. I know. I know. I feel bad about that. Here's what gives me a little bit of hope, I would say, is young people give me hope. They are smart. They are engaged. They want to change the world. I don't think they know how to, but I like their energy. There's an intention. Yeah. I like their intention. That's a good word. I like their spirit and I wish them well. Because, you know, what I tell them is, we screwed up this world for you in one way, you'll screw it up for another one, but you need to fix our problems before you do that. But I, you know, I love being on a university campus because young people are inspiring. They really are, despite the TikTok thing. All right. Thank you so much. Thank you. That was Hani Farid in conversation with me, Elise Hu, at TED 2025. You can check out Hani's talk on the TED Talks Daily feed and at TED.com. And that's it for today. TED Talks Daily is part of the TED Audio Collective. This episode was produced by Lucy Little and edited by Alejandra Salazar. This episode was recorded by Rich Amies and Dave Pulmer of Field Trip, production support from Daniela Ballarezzo and Shu Han Hu. The TED Talks Daily team includes Martha Estefanos, Oliver Friedman, Brian Green, and Tansika Sungmer Nivang. I'm Elise Hu. I'll be back tomorrow with a fresh idea for your feed. Thanks for listening. Okay. Fantastic. You were great. I'm still trying to think what I brought into my life in 2025. I know. Some of these are stumpers. I think I drink a lot more. And then... A lot of bourbon. A lot of bourbon. Alcoholism. Yeah, that's right. Functioning alcoholism. That's funny. Scientists at Alphabet's moonshot factory tackle big, serious global problems, but their leader likes to show up on rollerblades, sometimes dressed as Gandalf. It's also my way of trying to disarm people and remind them humor and silliness are very close to the wellsprings of creativity. How Astro Teller leads scientists to their breakthroughs. That's next time on the TED Radio Hour podcast from NPR. Subscribe or listen to the TED Radio Hour wherever you get your podcasts. The Genesis while due to the fun with the friend of mine.