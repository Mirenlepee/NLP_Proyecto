 you're listening to TED Talks Daily, where we bring you new ideas and conversations to spark your curiosity every day. I'm your host, Elise Hu. Earlier this week, we shared an explosive talk from investigative journalist Carol Cadwallader about a fast-moving technological coup threatening democracies around the world. Make sure to check that out in your feeds. Today, we're bringing you an extended conversation between Carol and Chris Anderson, the head of TED. Chris and Carol sat down to dig into the rise of techno-oligarchies and the vast implications of living in an era of data surveillance. They reflect on whether progress and privacy can coexist and why Silicon Valley's favorite mantra, move fast and break things, could be more dangerous than we think. That conversation is coming up. Carol Cadwallader, it's so nice to get to sit down with you. A few days ago, you opened the TED conference with an absolute blockbuster of a talk, got a huge reaction from people. In a one-sentence summary, and I'd like you to expand on this, what you argued was that we're in the middle of what looks like a digital coup, that the combination of Trump and a collection of big tech leaders is in danger of creating a new kind of autocracy in America. Is that about the core of it? Yes, yes, that's right. Well, I mean, you know, I put up the photo from the inauguration, and one of the things that I found really resonated with people, which is, so it's the photo of the tech leaders behind Trump. And, you know, I called it tech bros in hostage situations. And it's this idea that Silicon Valley has been captured by the administration, and the administration is acting in all sorts of unlawful ways. And Silicon Valley is now part of that. And the main way in which Silicon Valley is helping advance this is what? Well, you know, I talked about, for example, for me, the big danger, danger moment was when, you know, the first weekend that the administration took office, Elon Musk sent his, I call them cyber troops into the US Treasury, where they gained unlawful access, they got access to the nation's data, it's financial data. And he now has that. And, you know, for me, as you know, as I know, I call it the crack cocaine of Silicon Valley is always data, you need data to feed the AI. And you never, you can never put it back. I mean, that's one of the whole things once you've got the data, when you've got the entire nation's data, you can't just put that genie back in the bottle. And that to me is that this is a power grab, which goes beyond any of the guardrails of democracy. And that's not just about now. You know, Silicon Valley, as we know, does not think in four year cycles. This is absolutely about a land grab for the future. That's what I was trying to say really goes beyond politics. So I think the probably the purpose of this conversation now is for me to gently try and play devil's advocate. I tell this, obviously, we're trying to be open tent. We want people of all political views and so forth to, we want to listen and, you know, treat with curiosity and respect and so forth. So I'm going to frame what a different view of what's happening might be and see what you make of it. One thing to say, first of all, is that Silicon Valley is not a thing. From inside Silicon Valley, they would probably all say, no, these are our competitors. Elon Musk, Mark Zuckerberg were both there, but they are competitive enemies, to say the least. And so, like you have, I think it was you who coined this powerful term, broligarchy. I believe so. I started using it a year ago and I was because it was like, oh, hold on a minute. What we're seeing here is this elite, this business elite, like oligarchy, but it's tech bros. And I was like, of course, it's broligarchy. Right. But so the way I think of an oligarchy is of a group of powerful people kind of acting in unison. And I think they would say that they are not acting in unison. Largely that, you know, they are competitive with each other. And maybe there are some aligned interests like having legislation that makes it easier for companies to expand dynamically and so forth. But that's one piece. Like if it was the case that they generally are competitors with each other, what's the sense in which you feel that they're acting, you know, sort of as a group? I don't think there's any conspiracy here. And I don't necessarily think they're acting as a group at all. And this is where I think it's really helpful to look at America now from the frame of understanding what has happened in other countries. I'm really sorry. I've got such a sore throat from talking so much. I apologise to everybody. So, you know, I think Russia is a template here for what is happening, which is the breed of, we call them oligarchs, right? They didn't agree with each other. They were suing each other. They were sometimes murdering each other. But it was they needed a relationship with Putin with power. And in some cases, it was about enriching themselves about creating opportunities. But a lot of the time, it was also just survival, which is and that's what I mean about them looking like hostages. There wasn't a choice, it feels to me in terms of who was up there on the dais at the inauguration. Trump knew that he needs Silicon Valley, because in a standard coup, when the military takes over, the junta takes over, the first thing you do is take over the radio station, right? You need to have the means of communication. And in this case, the means of communication are these big Silicon Valley companies. It's such a, you know, colossal thing that is happening right now. It's not just America. Of course, we can see that in many ways. But you know, the fact is, these are global communication platforms. And they are now in an alignment, captured, whatever you want to talk about it with what is a coming autocratic regime. Right. So they, even though they're in competition with each other, you're saying that they, they share a need to have the president's approval. So they're doing things to win that approval, and thereby they're helping to construct and empower the creation of a kind of autocracy. I mean, Trump was explicit in his threats, right? I think he sort of threatened Zuckerberg with jail. You know, it's partly carrot, but it is partly stick, you know, and that is understood. I think that there is, there is both the carrot, which is there are opportunities, it's going to tear at regulation, it's going to make it much easier to do the things that they want to do. But there is also the, we can see that if you're not obeying, then life is going to be very difficult. And we see that playing out in all sorts of ways. So for example, with media organizations, we're seeing lawsuits on a daily basis, we're seeing it against big legal firms. That's one of the most shocking things for people. So it's not just they're sucking up to Trump for the sake of it, they feel they don't have a choice. It's unquestionably true that there was a big swing in Silicon Valley that has traditionally been left of center toward Trump over the last six months of the last campaign. If you talk to people there, most of them, I think, would have explained it as follows. They would have said two things. One, these companies are reacting against years of sort of progressive culture that they didn't like, that got in the way of building the stuff that they wanted to build. And a belief that the deregulation commitments of Trump and the explicit effort he made to do things like embrace crypto and so forth showed that he was interested in having a sort of a positive environment in which technology could flourish. And from that standpoint, like a defender of Elon would say, look, Elon is known for running businesses more efficiently than anyone on the planet. Cut 75, 80% of the workforce at Twitter, and at least operationally, functionally, added features and so forth. So what they would say is it's fantastic and amazing to have, for the first time, really, a really powerful businessman come into government and apply some of the tools to save what are, you know, crazy wasted costs in government, probably by common consent. And that the key to do that is that you have to start with the actual information systems. That's the pathway to do that. So what might look like, oh, he's going in to seize the data for his own use is not that it's delivering the means to figure out how to make the cuts. Is there, do you see any rationale for that at all? I could absolutely see from an engineer's brain that looks totally, completely rational and absolutely, and why wouldn't you? And also, if you're an engineer, as we've seen in Silicon Valley, laws, regulation, you know, sod that we know how to do it better. We know how to do it faster. If we do it quick enough, then actually it'll take them ages to catch up with us and we've already done it. Like that is the history of Silicon Valley. Move fast and break things. You know what though? We've got to stop using that phrase. It sounds so innocent and it's like, oh, it's like a baby breaking its toys. What that means is breaking the law and getting away with it. It's having absolute impunity and knowing that it takes ages for regulators to catch up. And that has created the situation that we're in. And this is exactly how DOGE is working. So everything that is done, for example, the cuts to USAID, devastating, devastating cuts. That is money which was allocated by Congress. This is not lawful. And this is to use the Silicon Valley framework. It's because they've always gotten away with it. So, you know, if you do it fast enough, it's then too late. The damage has been done and the world moves on. And that is the mistake that we have made with Silicon Valley time and time again. And it's why now, whilst this is happening in real time, this is the moment that people have to act. Because if you want to take the lessons from authoritarian countries, then it's too late after the fact. The longer that this goes on, the longer that the breaking, the wrecking, the vandalism, the illegal and unlawful behaviour goes on, it's more is consolidated, the harder it is to fight back. And so my talk in essence was about the fact that even though it's confusing, people are in denial, they feel powerless. You know, there's this sort of moment of paralysis, but actually, people do have power. And that was what I was trying to communicate in my talk, really, as somebody who has experienced powerlessness. And I think, you know, as I said, it was only coming to TED that I had this revelation about, actually, when you're at your most powerless, it's often because you are powerful. That's why you have to be stopped. And the people of America are more powerful than these guys, right? There's more of you. And you have values and morals on your ethics, you know, a belief in the law on your side. So that's the thing that I was trying to communicate. Well, you really touched a nerve in the most powerful way by being eloquent, as you just heard, and by being vulnerable and, you know, coming at it from a very personal space. And I, when it comes to the demolition of USAID, I mean, I personally know organisations of people who were wrecked by that. And I think history will show that that was a pretty brutal and reckless approach. So can I turn the tables, Chris, and ask you about that? Because, you know, TED has done this amazing thing of bringing together innovators, plus also people who think about the really hard problems that the world faces. And it's always been about a sort of synthesis between those and finding new ways. And this spirit of optimism has always run through the place. And for me personally, you know, it's been a big thing. I first came to TED in 2005. But this is something really different, isn't it? And do you find it hard to retain your optimistic frame? I've always described myself as a determined optimist, which means that no matter how dark things are, you look for a pathway forward that has some hope. And you try and shine a light on it. And hopefully, you know, you can find your way there. I've always believed that the worlds of ideas, innovation, technology are actually ultimately more powerful than politics. And I'm dismayed at the world of politics right now, dismayed at it, because it seems pretty helpless. There seems to be an impossible divide between two tribes. I actually think that over the next three or four years, the even bigger story will be how technology plays out. Because I think AI is growing in power at such a speed that it will be more important than the political decisions are made. So for me, my focus is, can we think of a way of ensuring that we get the best of AI and not the worst? And that takes us, I think, into one of the key conversations I want to have with you is around data. In your talk, you so powerfully talked about how these companies are extracting our data. It's surveillance, capitalism, surveillance, fascism, I think you called it. I cut that line. You know, can I just say that? I was really sad. When I woke up the next morning, I was really sad because I had that line in there of like, this is no longer surveillance, capitalism. We're on our pathway to surveillance, fascism. But because I was like mindful that everybody was like, you've got to cut it down a bit. So I lost that. And it was one of my, it was like, you know, you said, well, there we go. We've got it back. We've got it back now. Thank you. But this is, I think, is such, it's something that like I'm wrestling with myself, because it's true that data, your data used by someone in power against your interest is a horrifying thing. It's also true that in a way, you know, everything works from data. You need information to have any kind of useful knowledge. So the sharpest way I can put this is this. Let's say I've got a very powerful AI companion, right, that I'm consulting and I'm getting wisdom from and so forth. And you ask the question, do I want it to know about me or not? I think most people will end up concluding that they do want that AI to know about them, because it's only by knowing about you that they can actually give you wise advice that's tailored to what you need and who you know. And it's almost like the classic sort of examples about the misuse of data around, you know, the advertiser knows before you do that you're, you know, you're a target for Viagra or for whatever, you know, ailment that they can foist on you. And it feels very uncomfortable. But when it comes to an actual intelligence that you're working with, I wonder whether you're going to win the argument on data or whether actually most people are actually going to voluntarily say, no, please, you know, literally, I want you to read all my emails and help me be wiser. Is that horrifying? Or do you see some logic to that? I understand the beautiful vision that that is, that there is a really helpful assistant who's going to know all your problems and, you know, help you reach the great solutions. It's the thing is about it is that first off is ownership, right? Who are these companies owned by? What are their values? Who are they aligned with? Where might that data end up? And do you trust them? And are they transparent about it? Do you know what's going to happen to that data where it could end up? And the thing is, is that in the current environment we're in, none of those things are true, right? There are none of these companies where you could say, yes, this person is the Nelson Mandela of the tech industry, and I have complete trust and faith in them. And even if there was, you know, the fact is, is that as we've seen with 23andMe, right? So people have done these genetic tests that this company now has their genetic code, and it's now up for sale. So where is that going to end up? And the thing is to go back to it, which is you'd never get your data back when it's gone, it's gone. And the ways that that can be weaponized against you, a lot of women in America are starting to understand what that means. These period tracking apps, which now you've understanding that's a surveillance device, that, you know, if there's some instance in which they might have to seek healthcare access, that that could become evidence which could be used against them. This is really personal information. And that's the thing, you know, a lot of people talk about data as property, and it's really so much more than that. It's like your blood, your bones, your skin, your cells, right? You have to think about how that can and will be, like assume the worst. Just at this point in time, you have to assume the worst. The business models of the AI platforms are different from the business models of social media. Social media was dependent on advertising, and the core there is almost like give the advertisers data that you've extracted and let them use it how they will. For the AI platforms to earn people's subscription, whether you're literally paying out an amount per month, I think they're going to conclude that it's in their interest to demonstrate that they are trustable. I mean, if they're not, people won't subscribe. But they're not trustworthy. Who's trustworthy in the AI space then, out of these companies? Who has been transparent, ethical, and legitimate in their approach to data use and the models they're building? Obviously, you know, the stated policies of all of the companies is that they want to honour users' interests. I mean, so I've spent time talking with Demis Hassabis, who's head of DeepMind and basically drives Google's most important AI efforts. I think he's an honourable person. I think he's trying really hard to do the right thing and to develop Google's AI products on fair principles. It's not to say it's an easy thing to do. But I also think even if you, like, let's say that you don't trust Sam Altman. If OpenAI is exposed as abusing data, they have literally already billions of dollars that will go out the door from people who won't continue to subscribe to them. So you can say that maybe some individual at the top is not trustable. What I'm saying is that the actual system here doesn't obviously pull towards mistrust. It actually pulls towards, like, it's key to win people's trust for them to succeed. But I think one of the best measures of people's behaviour in the future is their behaviour in the past. And this is actually how a lot of these systems work, right? And if you look at the behaviour of OpenAI in the past, which is it illegally scraped data from numerous sources without respecting property rights or any other laws in different jurisdictions. Well, you had that beautiful point in your talk where you said, so I asked ChatGPT to write a TED talk in the style of Carol Cadwallader. And you showed what was... Yeah, it was basically the outline of my talk. It was compelling. Could have saved you a lot of time, Carol. Except, as I said, it's like the opposite of human creativity. Well, so let me ask this, though. You said, you know, I did not consent to this, and I do not consent. And it feels like, you know, you've had... It just feels outrageous that they've been reading all your stuff and are now doing this. And anyone else could write a talk in the style of Carol Cadwallader. Would you feel differently about it if there was an improved business model here where the platform's committed to respecting individual talent? So that, for example, when a request is made to specifically embody the style of a musician or a writer or an artist, that actually that there would be some compensation back to that person so that you could say, actually, this is a way in which I could amplify my impact on the planet and I will actually be compensated for it. Does that change the... So I think that's fundamental to it. But however, it's just like you go back to the point is that this was done without any of our permission, right? And so we can see that there are big players who are being able to make deals. Right. So, and I use the Guardian as an example of that, right? Which is the Guardian has done this syndication deal after the fact. Right. Because the damage has already been done. They've already scraped the entirety of the Guardian's website. So I understand the logic. It's like, well, you might as well try and make some money out of it. But of course, that's not respecting of the IP and of individual contributors there. And individual contributors are not going to be in a position to do these deals with the platforms because they've got no, there's no collective ability to force a proper negotiation. So in a theoretical world with an ethical AI company, which asked your permission before it scraped your data and then paid you whenever it used that in some ways. But as we know, it's like, it's so hard to make that assessment, right? Because it's taken in such vast amounts of data and then it's mixed it all up into some weird sausage, which it's now putting back out there. I mean, they would argue, and I'm not saying I agree with this, but they would argue that every time technology changes, that the rules need to be worked out again, that you've got a situation where, you know, your words were published, put out freely for anyone on the internet to read, no matter how many more people read your past words, you don't get any more payment. And so the data is out there, they would argue that it's out there as a sort of public resource for fair use. And I think it's right that people are challenging that because the fact is that say, a given artist could easily be displaced by AI able to do much more. It's actually, no, no, no, it's actually much, much deeper than that, right? Which is that every nation state in the world has some form of property law, right? Which is you can't walk into somebody's house and just steal the silver. That's what are fundamentally like is the basis of law and order in our countries. But when it's intellectual... And this is, no, it's just, it's property. These are property laws. You know, in Britain, we've had this law since 1783. And if you can't respect the basic fundamental underlying principles with which we order society, which is do not steal, then what are you left with? It's like, it's fine. We're going to take your silver. And then if we sell it on eBay, we might give you like 5% of it. Yeah. So I get the anger. There is a difference between a physical object where if you steal it, that person doesn't have it versus a digital property where if you quote, steal it, you still have access to it. There's no difference. Well, you know, I think there's traditionally a difference in like when an idea is out there, it can be built on an amplified. And like, for example, in the music business, there's constant building on one person's work by the next artist. The kindest way of viewing what they're doing is for them is to say, we're not stealing, we're amplifying. I think we are absolutely lost if we do not respect the law. And that's what we're seeing. This is what is happening. But the law isn't defined yet properly in A&M. It's in the process of being defined. The law, it's property. These are just property laws. There's no difference. Right. And it's the point to go back to the case, right? You know, the underlying basis of what Google did with it, where it digitized, it stole, you know, every single written book in the world, didn't it? That was one of its first acts. And as I sort of said, it's just this acting with impunity has led us to a place where that ideology is now embedded in the government of the biggest superpower in the world. And that is what's playing out now in real time. And if you don't like those laws, well, then you don't respect these ones either. And this is where we're in a sort of cascading situation. Right, right. Well, okay. I want two things simultaneously. I want a world in which creators are respected and fairly compensated for what they do. I also want a world where I can search for the collective wisdom of humanity and find it. I want to be able to read from all these books and discover them. And so because... But we're not going to be able to have any further wisdom, because there's going to be no economic model for anybody to write another book. Where I agree with you is that artists absolutely and writers should be compensated. And if we could do that, it's just about possible to imagine a world where AI data can actually amplify the best thinkers. You know, the fact that in principle, someone's kid could have a conversation with Einstein based on his wisdom, you know, that's not something possible before now. Arguably, that makes the world better. You know, I think it's a reasonable conversation. But I think most people here would agree that the law is not yet in a good place and that writers and artists are in severe danger of being... It's not in severe danger. It's happened. And also, I think going back to it, which is it's power. I think we just keep on having to come back with it's power. This is power being concentrated in the hands of a very few companies, which are now aligned with a rogue state. That is what America is now in the world. It is a rogue state. You know, one of the key things I wanted to get across in the talk is that technology is politics now and politics is technology. There is no separation between them. I really appreciate, Chris. It was so punchy of you to... And we should talk about why you decided to put me first as the opening talk of the conference. Tell me, why did you decide that? I put you first because there are a huge number of people, probably the large majority of certainly the tech community, is in a bit of a state of shell shock right now. I mean, the pace of change has not been seen before, either politically or technologically, and people don't know what to make of it. And you are unbelievably eloquent at naming it and helping people feel it. You expressed emotions and feelings that so many people in the room feel. They were just so moved to hear that come from someone so powerfully. And, you know, you don't hold back. Most people are frightened to make bold accusations against named individuals. You're fearless. I would actually love you, just speaking of the journey that you've been on, to just explain a bit more your own story here. Because you mentioned in the talk briefly that the last time you spoke, you know, you'd end up being sued and that it turned your life upside down. In that original talk, you described someone as a liar based on prior reporting, and he sued you for that. What was the court ruling there? At some point, the court ruled that you would have to pay his legal costs. What it is, is that I said words which we published in The Guardian, which were perfectly defensible, which was that he had lied about his relationship with the Russian government. And that was based upon this series of non-disclosed meetings, let's just say, that the Brexit donor had with Russian embassy officials in the lead up to the Brexit vote. Now, that is, that's just fact. And it was in our reporting. But the thing which I got tripped up on, Chris, which is that in the very arcane meshes of British libel law, a single judge decides on the meaning of your words. And they take into context the entire talk. And then they formulate their view of that meaning for all time. So the judge came up with this formulation, which is that he had accepted money in contravention of the law on such. And so therefore, I had libeled because I'd made an accusation that he'd accepted foreign funding. What it meant is that I had never said these words at any point. Those words were never said in the talk. I certainly never meant to say those words. But that's what I had to go into court to defend. And that is why it was the Kafkaesque quality of it, which was so confounding, because I was having to defend something which I'd never said. And that was where it turned the case on its head. Because it meant I couldn't defend that judge's meaning. So I then had to defend on the public interest of why I gave the talk. And it put all of the onus on me and my reporting. And that's why instead of me getting to do discovery on the man, he got to do discovery on me. And that was when I talked about, because this is the thing which is really relevant. There's various things which are really relevant to what's going on in the US right now. The court case was called a slap, which means that it's a way of trying to shut down critical reporting or critical voices. And that's what we're seeing happening in the US, these weaponised lawsuits. Organisations across America are now preparing for this to happen to them. They know that they are going to be on the end of highly politicised lawsuits in which they're going to have to open up their computers, their laptops. And they also know this is going to be accompanied, as it was in my case, by a sort of massive online hate campaign. And so that's the analogy which I was trying to make, which is what happened to me is a warning for what is coming for other people in America. Well, needless to say, for everyone at TED, it was horrifying to see what you went through. And I won. So just to be clear on that, I won the case. The public interest was found to be, my talk was absolutely lawful at the time that I gave it. And then on appeal, what happened is in the one year after I gave that talk, a police investigation into the Brexit donor was voided. And at that point, the Court of Appeal decided that the defence fell away. So it was the continued publication by TED, which is a foreign media organisation in a foreign jurisdiction I was held responsible for. And that's why he got damages awarded against him. And that's the thing which we're now appealing at the European Court of Human Rights. The thing is, it was complicated. Nobody really understood it. It was the pandemic. And, you know, I think when you realise the gravity of what was happening, you rang me up after the trial had ended and made that very generous gesture, which I do really appreciate, which is you said, you know, we will see you right. Yes. So thank you for that. It wasn't, I don't want that to go unremarked. I mean, you're, you're an amazing fighter. So Carol, during your talk, you referred to the terrible personal experience you had the last few years after your last talk. For someone who wants to understand more about what happened there, where can they go? So I am in one week's time leaving my job, not through choice, but because 100 journalists from The Guardian, we're being terminated because The Guardian has sold our corner of it. So I have set up a sub stack and I will write a full account where I would love to be able to explain to people the bigger picture behind that. I really, really believe in independent journalism. I really believe in independent media and independent film. And that I think is so vital at this time. And so, as I was saying, my newspaper has been bought by unknown, unclear investors, and I don't feel it's possible to do the same kind of independent journalism there. But you know, there is an explosion. There's a thirst and demand from people for, I think, these like clear, independent voices. And I think out of the total crisis of media and what is happening, social media, you know, information chaos, I call it, I do also think there is an opportunity there to grow properly sustainable media from the ground up, supported by readers who value that, without being dependent upon advertising, which we've seen has been a terrible media game, and algorithms, which we've seen as another terrible game. So I sort of, you know, I really hope that people understand that trusted sources of information are vital, and we need to pay for them. And yeah, that's my message, I suppose. Yeah. Carol, thank you so much for coming to TED. Took lots of courage. You really touched people. Really wish you well as you continue your journey. Thank you, Chris. Thank you for having me. I really appreciate it. That was Carol Cadwallader in conversation with head of TED, Chris Anderson at TED 2025. You can check out Carol's talk on the TED Talks Daily feed or on TED.com. And that's it for today. TED Talks Daily is part of the TED Audio Collective. This episode was produced by Lucy Little, edited by Alejandra Salazar, and fact-checked by Julia Dickerson. This episode was recorded by Rich Amies and Dave Pulmer of Field Trip and mixed by Lucy Little. Production support from Daniela Ballarezzo and Shu Han Hu. The TED Talks Daily team includes Martha Estefanos, Oliver Friedman, Brian Green, and Tansika Sangmarnivang. Additional support from Emma Taubner. I'm Elise Hu. I'll be back tomorrow with a fresh idea for your feed. Thanks for listening. I'll see you next time. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye. Bye.